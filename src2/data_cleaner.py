import pandas as pd
import numpy as np
import re
import sqlite3
from datetime import datetime
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataCleaner:
    """
    Classe pour nettoyer et agrÃ©ger les donnÃ©es du projet de classification
    """
    
    def __init__(self):
        self.cleaning_rules = {
            'remove_duplicates': True,
            'remove_empty_products': True,
            'normalize_categories': True,
            'fix_prices': True,
            'validate_dates': True
        }
    
    def clean_product_names(self, df):
        """
        Nettoie les noms de produits
        """
        logger.info("ðŸ§¹ Nettoyage des noms de produits...")
        
        if 'Produit' in df.columns:
            # Supprimer les lignes avec produits vides
            initial_count = len(df)
            df = df.dropna(subset=['Produit'])
            df = df[df['Produit'].str.strip() != '']
            
            # Normaliser les noms
            df['Produit'] = df['Produit'].str.lower()
            df['Produit'] = df['Produit'].str.strip()
            
            # Supprimer les caractÃ¨res spÃ©ciaux excessifs
            df['Produit'] = df['Produit'].apply(lambda x: re.sub(r'[^\w\s\-\.]', ' ', x))
            df['Produit'] = df['Produit'].apply(lambda x: re.sub(r'\s+', ' ', x))
            
            # Supprimer les doublons
            df = df.drop_duplicates(subset=['Produit'])
            
            logger.info(f"âœ… Produits nettoyÃ©s: {initial_count} â†’ {len(df)}")
        
        return df
    
    def normalize_categories(self, df):
        """
        Normalise les catÃ©gories de produits
        """
        logger.info("ðŸ“‚ Normalisation des catÃ©gories...")
        
        if 'Categories_OFF' in df.columns:
            # Mapping des catÃ©gories similaires
            category_mapping = {
                'fruits & legumes': 'Fruits & LÃ©gumes',
                'fruits et legumes': 'Fruits & LÃ©gumes',
                'fruits': 'Fruits & LÃ©gumes',
                'legumes': 'Fruits & LÃ©gumes',
                'viande': 'Viandes & Charcuterie',
                'viandes': 'Viandes & Charcuterie',
                'charcuterie': 'Viandes & Charcuterie',
                'poisson': 'Poisson & Fruits de mer',
                'fruits de mer': 'Poisson & Fruits de mer',
                'laitier': 'Produits laitiers',
                'laitiers': 'Produits laitiers',
                'yaourt': 'Produits laitiers',
                'fromage': 'Produits laitiers',
                'boisson': 'Boissons',
                'boissons': 'Boissons',
                'soda': 'Boissons',
                'epicerie': 'Ã‰picerie salÃ©e',
                'epicerie salee': 'Ã‰picerie salÃ©e',
                'sucre': 'Ã‰picerie sucrÃ©e',
                'sucree': 'Ã‰picerie sucrÃ©e',
                'chocolat': 'Ã‰picerie sucrÃ©e',
                'hygiene': 'HygiÃ¨ne',
                'entretien': 'Entretien / MÃ©nage',
                'menage': 'Entretien / MÃ©nage'
            }
            
            # Appliquer le mapping
            df['Categories_OFF'] = df['Categories_OFF'].str.lower()
            df['Categories_OFF'] = df['Categories_OFF'].map(category_mapping).fillna(df['Categories_OFF'])
            
            # Capitaliser correctement
            df['Categories_OFF'] = df['Categories_OFF'].str.title()
            
            logger.info(f"âœ… CatÃ©gories normalisÃ©es: {df['Categories_OFF'].nunique()} catÃ©gories uniques")
        
        return df
    
    def fix_prices(self, df):
        """
        Corrige et valide les prix
        """
        logger.info("ðŸ’° Correction des prix...")
        
        price_columns = ['Prix', 'prix_total', 'budget']
        
        for col in price_columns:
            if col in df.columns:
                # Convertir en numÃ©rique
                df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # Supprimer les prix nÃ©gatifs ou trop Ã©levÃ©s (>10000â‚¬)
                df = df[(df[col].isna()) | ((df[col] >= 0) & (df[col] <= 10000))]
                
                # Arrondir Ã  2 dÃ©cimales
                df[col] = df[col].round(2)
                
                logger.info(f"âœ… Prix corrigÃ©s pour {col}")
        
        return df
    
    def validate_dates(self, df):
        """
        Valide et corrige les dates
        """
        logger.info("ðŸ“… Validation des dates...")
        
        date_columns = ['date_achat', 'date_enregistrement', 'collected_at']
        
        for col in date_columns:
            if col in df.columns:
                # Convertir en datetime
                df[col] = pd.to_datetime(df[col], errors='coerce')
                
                # Supprimer les dates futures ou trop anciennes (>10 ans)
                current_date = pd.Timestamp.now()
                df = df[(df[col].isna()) | 
                       ((df[col] <= current_date) & 
                        (df[col] >= current_date - pd.DateOffset(years=10)))]
                
                logger.info(f"âœ… Dates validÃ©es pour {col}")
        
        return df
    
    def remove_corrupted_entries(self, df):
        """
        Supprime les entrÃ©es corrompues
        """
        logger.info("ðŸš« Suppression des entrÃ©es corrompues...")
        
        initial_count = len(df)
        
        # Supprimer les lignes avec trop de valeurs manquantes (>50%)
        threshold = len(df.columns) * 0.5
        df = df.dropna(thresh=threshold)
        
        # Supprimer les lignes avec des valeurs aberrantes
        if 'Prix' in df.columns:
            # Prix nÃ©gatifs ou trop Ã©levÃ©s
            df = df[(df['Prix'].isna()) | ((df['Prix'] >= 0) & (df['Prix'] <= 10000))]
        
        if 'Produit' in df.columns:
            # Produits avec des noms trop courts ou trop longs
            df = df[df['Produit'].str.len() >= 2]
            df = df[df['Produit'].str.len() <= 200]
        
        logger.info(f"âœ… EntrÃ©es corrompues supprimÃ©es: {initial_count} â†’ {len(df)}")
        
        return df
    
    def aggregate_data_sources(self, csv_files, output_file="data/aggregated_data.csv"):
        """
        AgrÃ¨ge les donnÃ©es de plusieurs sources
        """
        logger.info("ðŸ”„ AgrÃ©gation des donnÃ©es de plusieurs sources...")
        
        all_data = []
        
        for file in csv_files:
            try:
                df = pd.read_csv(file, sep=';')
                df['source'] = file
                all_data.append(df)
                logger.info(f"âœ… Fichier chargÃ©: {file} ({len(df)} lignes)")
            except Exception as e:
                logger.error(f"âŒ Erreur lors du chargement de {file}: {e}")
        
        if all_data:
            # ConcatÃ©ner tous les DataFrames
            aggregated_df = pd.concat(all_data, ignore_index=True)
            
            # Nettoyer les donnÃ©es agrÃ©gÃ©es
            aggregated_df = self.clean_all_data(aggregated_df)
            
            # Sauvegarder
            aggregated_df.to_csv(output_file, index=False, sep=';')
            logger.info(f"âœ… DonnÃ©es agrÃ©gÃ©es sauvegardÃ©es: {output_file} ({len(aggregated_df)} lignes)")
            
            return aggregated_df
        
        return None
    
    def clean_all_data(self, df):
        """
        Applique tous les nettoyages sur un DataFrame
        """
        logger.info("ðŸ§¹ Application du pipeline de nettoyage complet...")
        
        initial_count = len(df)
        
        # 1. Supprimer les entrÃ©es corrompues
        df = self.remove_corrupted_entries(df)
        
        # 2. Nettoyer les noms de produits
        df = self.clean_product_names(df)
        
        # 3. Normaliser les catÃ©gories
        df = self.normalize_categories(df)
        
        # 4. Corriger les prix
        df = self.fix_prices(df)
        
        # 5. Valider les dates
        df = self.validate_dates(df)
        
        # 6. Supprimer les doublons finaux
        df = df.drop_duplicates()
        
        logger.info(f"ðŸŽ‰ Nettoyage terminÃ©: {initial_count} â†’ {len(df)} lignes")
        
        return df
    
    def generate_cleaning_report(self, df_before, df_after):
        """
        GÃ©nÃ¨re un rapport de nettoyage
        """
        report = {
            'lignes_avant': len(df_before),
            'lignes_apres': len(df_after),
            'lignes_supprimees': len(df_before) - len(df_after),
            'taux_reduction': round((len(df_before) - len(df_after)) / len(df_before) * 100, 2),
            'categories_uniques': df_after['Categories_OFF'].nunique() if 'Categories_OFF' in df_after.columns else 0,
            'produits_uniques': df_after['Produit'].nunique() if 'Produit' in df_after.columns else 0
        }
        
        logger.info("ðŸ“Š Rapport de nettoyage:")
        for key, value in report.items():
            logger.info(f"  {key}: {value}")
        
        return report

if __name__ == "__main__":
    cleaner = DataCleaner()
    
    # Exemple d'utilisation
    print("ðŸ§¹ Test du pipeline de nettoyage")
    print("=" * 40)
    
    # Charger des donnÃ©es d'exemple
    try:
        df = pd.read_csv("data/tickets_categorie_final.csv", sep=';')
        print(f"ðŸ“‚ DonnÃ©es chargÃ©es: {len(df)} lignes")
        
        # Nettoyer
        df_clean = cleaner.clean_all_data(df)
        
        # Rapport
        cleaner.generate_cleaning_report(df, df_clean)
        
    except FileNotFoundError:
        print("âŒ Fichier de donnÃ©es non trouvÃ©. CrÃ©ez d'abord des donnÃ©es d'exemple.") 